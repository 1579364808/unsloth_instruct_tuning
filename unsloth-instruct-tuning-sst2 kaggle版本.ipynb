{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install unsloth openai\n","metadata":{"ExecuteTime":{"end_time":"2025-03-15T16:38:50.833887Z","start_time":"2025-03-15T16:38:50.825632Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T02:05:03.413017Z","iopub.execute_input":"2025-03-16T02:05:03.413301Z","iopub.status.idle":"2025-03-16T02:07:56.125506Z","shell.execute_reply.started":"2025-03-16T02:05:03.413264Z","shell.execute_reply":"2025-03-16T02:07:56.124394Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n# os.environ['HF_HOME'] = '/root/autodl-tmp/cache/'\n# os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"","metadata":{"ExecuteTime":{"end_time":"2025-03-15T16:38:50.950364Z","start_time":"2025-03-15T16:38:50.932539Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T02:08:54.326329Z","iopub.execute_input":"2025-03-16T02:08:54.326618Z","iopub.status.idle":"2025-03-16T02:08:54.330122Z","shell.execute_reply.started":"2025-03-16T02:08:54.326598Z","shell.execute_reply":"2025-03-16T02:08:54.329144Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport torch\nfrom unsloth import FastLanguageModel\nfrom datasets import load_dataset\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom openai import OpenAI\nimport time\nfrom tqdm import tqdm\n","metadata":{"ExecuteTime":{"end_time":"2025-03-15T16:39:03.253876Z","start_time":"2025-03-15T16:38:51.105012Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T02:08:56.588922Z","iopub.execute_input":"2025-03-16T02:08:56.589195Z","iopub.status.idle":"2025-03-16T02:09:25.695288Z","shell.execute_reply.started":"2025-03-16T02:08:56.589175Z","shell.execute_reply":"2025-03-16T02:09:25.694598Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 读取环境变量中的 API Key  Kaggle 方式读取 API Key\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\n# 获取 DeepSeek API Key\napi_key = user_secrets.get_secret(\"DeepSeek_API_KEY\")\n\n\nclient = OpenAI(\n    api_key=api_key,\n    base_url=\"https://api.deepseek.com\"\n)\n","metadata":{"ExecuteTime":{"end_time":"2025-03-15T16:43:45.902165200Z","start_time":"2025-03-15T16:39:03.316943Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T02:09:41.929028Z","iopub.execute_input":"2025-03-16T02:09:41.929352Z","iopub.status.idle":"2025-03-16T02:09:42.129795Z","shell.execute_reply.started":"2025-03-16T02:09:41.929325Z","shell.execute_reply":"2025-03-16T02:09:42.128909Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"max_seq_length = 2048\ndtype = torch.float16  # 适用于 4-bit 量化\nload_in_4bit = True\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"unsloth/DeepSeek-R1-Distill-Llama-8B\",\n    max_seq_length=max_seq_length,\n    dtype=dtype,\n    load_in_4bit=load_in_4bit,\n)\n","metadata":{"ExecuteTime":{"end_time":"2025-03-15T16:39:31.748026Z","start_time":"2025-03-15T16:39:03.437374Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T02:09:44.604523Z","iopub.execute_input":"2025-03-16T02:09:44.604836Z","iopub.status.idle":"2025-03-16T02:10:11.824487Z","shell.execute_reply.started":"2025-03-16T02:09:44.604811Z","shell.execute_reply":"2025-03-16T02:10:11.823579Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"prompt_style = \"\"\"Below is an instruction that describes a task, paired with\nan input that provides further context.\nWrite a response that appropriately completes the request.\nBefore answering, think carefully about the question and create a step-by\nstep chain of thoughts to ensure a logical and accurate response.\n### Instruction:\nYou are an expert in sentiment analysis with advanced knowledge in understanding\nand interpreting emotions from text.\nPlease analyze the sentiment of the following text and output 0 (negative) or 1 (positive).\n### Text:\n{}\n### Response:\n<think>{}\"\"\"\n\ntrain_prompt_style = \"\"\"Below is an instruction that describes a task, paired with\nan input that provides further context.\nWrite a response that appropriately completes the request.\nBefore answering, think carefully about the question and create a step-by\nstep chain of thoughts to ensure a logical and accurate response.\n### Instruction:\nYou are an expert in sentiment analysis with advanced knowledge in understanding\nand interpreting emotions from text.\nPlease analyze the sentiment of the following text and output 0 (negative) or 1 (positive).\n### Text:\n{} \n### Response: \n<think> \n{} \n</think> \n{}\"\"\"\n","metadata":{"ExecuteTime":{"end_time":"2025-03-15T16:39:31.819448Z","start_time":"2025-03-15T16:39:31.813417Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T02:10:15.294229Z","iopub.execute_input":"2025-03-16T02:10:15.294525Z","iopub.status.idle":"2025-03-16T02:10:18.699225Z","shell.execute_reply.started":"2025-03-16T02:10:15.294504Z","shell.execute_reply":"2025-03-16T02:10:18.698248Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\nimport time\n\ndef generate_cot(text, label, max_retries=10):\n    \"\"\"\n    生成思维链的函数，使用二进制指数退避策略进行 API 调用重试。\n    :param text: 需要分析的文本\n    :param label: 情感标签（0/1）\n    :param max_retries: 最大重试次数\n    :return: 生成的 CoT 字符串\n    \"\"\"\n    sentiment_map = {0: \"negative\", 1: \"positive\"}\n\n    prompt = f\"\"\"As a sentiment analysis expert, generate a step-by-step Chain of Thought (CoT) in English to explain why the following text is {sentiment_map[label]}. \nThe CoT should follow this structure:\n1. Identify key sentiment-bearing words/phrases\n2. Analyze contextual clues\n3. Consider linguistic patterns\n4. Synthesize overall sentiment\n5. Conclude with the final sentiment label (0 for negative, 1 for positive)\n\nText: {text}\nCoT:\"\"\"\n\n    base_delay = 2  # 初始等待时间\n    for attempt in range(max_retries):\n        try:\n            response = client.chat.completions.create(\n                model=\"deepseek-chat\",\n                messages=[\n                    {\"role\": \"system\", \"content\": \"You are an expert in sentiment analysis and logical reasoning.\"},\n                    {\"role\": \"user\", \"content\": prompt}\n                ],\n                temperature=0.4,\n                max_tokens=300,\n                stream=False\n            )\n            return response.choices[0].message.content.strip()\n        except Exception as e:\n            if attempt < max_retries - 1:\n                wait_time = base_delay * (2 ** attempt) + random.uniform(0, 1)  # 指数退避 + 随机抖动\n                print(f\"Attempt {attempt+1} failed, retrying in {wait_time:.2f} seconds...\")\n                time.sleep(wait_time)\n            else:\n                print(f\"Failed after {max_retries} attempts: {str(e)}\")\n                return \"CoT generation failed\"\n\n","metadata":{"ExecuteTime":{"end_time":"2025-03-15T16:39:31.914614Z","start_time":"2025-03-15T16:39:31.906027Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def add_cot_to_dataset(dataset, sample_size=None):\n    \"\"\"\n    为数据集添加CoT字段\n    :param dataset: 原始数据集\n    :param sample_size: 采样数量（测试时使用）\n    :return: 包含CoT的新数据集\n    \"\"\"\n    texts = dataset[\"sentence\"]  # SST-2数据集的文本字段是\"sentence\"\n    labels = dataset[\"label\"]\n\n    cots = []\n    for text, label in tqdm(zip(texts, labels), total=len(texts)):\n        cot = generate_cot(text, label)\n        cots.append(cot)\n        time.sleep(1)  # 控制API调用频率\n\n    return dataset.add_column(\"Complex_CoT\", cots)\n","metadata":{"ExecuteTime":{"end_time":"2025-03-15T16:39:32.012681Z","start_time":"2025-03-15T16:39:32.005221Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = load_dataset(\"glue\", \"sst2\", split=\"train[:500]\")#使用500条数据训练\n\n# 生成CoT数据\nenhanced_dataset = add_cot_to_dataset(dataset)\n","metadata":{"ExecuteTime":{"end_time":"2025-03-15T16:42:55.613032Z","start_time":"2025-03-15T16:39:32.114559Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token\n\ndef formatting_prompts_func(examples):\n    inputs = examples[\"sentence\"]\n    cots = examples[\"Complex_CoT\"]\n    outputs = examples[\"label\"]\n    texts = []\n    for input, cot, output in zip(inputs, cots, outputs):\n        text = train_prompt_style.format(input, cot, output) + EOS_TOKEN\n        texts.append(text)\n    return {\n        \"text\": texts,\n    }\n\nformatted_dataset = enhanced_dataset.map(formatting_prompts_func, batched=True)\n","metadata":{"ExecuteTime":{"end_time":"2025-03-15T16:42:55.729158Z","start_time":"2025-03-15T16:42:55.712018Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(formatted_dataset[0]['Complex_CoT'])","metadata":{"ExecuteTime":{"end_time":"2025-03-15T16:42:55.830350Z","start_time":"2025-03-15T16:42:55.822925Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(formatted_dataset[0]['text'])","metadata":{"ExecuteTime":{"end_time":"2025-03-15T16:42:55.921500Z","start_time":"2025-03-15T16:42:55.916878Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def inference_example(text):\n    FastLanguageModel.for_inference(model)\n    inputs = tokenizer([prompt_style.format(text, \"\")], return_tensors=\"pt\").to(\"cuda\")\n    outputs = model.generate(\n        input_ids=inputs.input_ids,\n        attention_mask=inputs.attention_mask,\n        max_new_tokens=1200,\n        use_cache=True,\n    )\n    response = tokenizer.batch_decode(outputs)\n    return response[0].split(\"### Response:\")[1]\n\n\n# 训练前推理示例\ntext = \"I absolutely loved the movie! The acting was superb and the storyline was captivating.\"\nprint(\"训练前推理结果：\")\nprint(inference_example(text))","metadata":{"ExecuteTime":{"end_time":"2025-03-15T16:43:03.477652Z","start_time":"2025-03-15T16:42:55.998400Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r=16,\n    target_modules=[\n        \"q_proj\",\n        \"k_proj\",\n        \"v_proj\",\n        \"o_proj\",\n        \"gate_proj\",\n        \"up_proj\",\n        \"down_proj\",\n    ],\n    lora_alpha=16,\n    lora_dropout=0,\n    bias=\"none\",\n    use_gradient_checkpointing=\"unsloth\",\n    random_state=3407,\n    use_rslora=False,\n    loftq_config=None,\n)\n","metadata":{"ExecuteTime":{"end_time":"2025-03-15T16:43:12.903737Z","start_time":"2025-03-15T16:43:03.542651Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    train_dataset=formatted_dataset,\n    dataset_text_field=\"text\",\n    max_seq_length=max_seq_length,\n    dataset_num_proc=2,\n    args=TrainingArguments(\n        per_device_train_batch_size=2,\n        gradient_accumulation_steps=4,\n        # Use num_train_epochs = 1, warmup_ratio for full training runs!\n        # warmup_steps=5,\n        # max_steps=60, #max_steps=60：总共训练 60 步（适用于短暂测试，完整训练一般使用 num_train_epochs）\n        num_train_epochs = 1,\n        warmup_ratio = 0.1,\n        learning_rate=2e-4,\n        # fp16=not is_bfloat16_supported(), #fp16=not is_bfloat16_supported()：如果不支持 bfloat16，就使用 fp16。\n        # bf16=is_bfloat16_supported(), #bf16=is_bfloat16_supported()：如果支持 bfloat16，就使用 bf16。\n        fp16=True,\n        logging_steps=10,\n        optim=\"adamw_8bit\",#采用 AdamW 优化器的 8-bit 版本（减少显存占用，提高大模型训练效率）\n        weight_decay=0.01,\n        lr_scheduler_type=\"linear\",\n        seed=3407,\n        output_dir=\"outputs\",\n        report_to=\"none\"  # 关闭 wandb\n    ),\n)\n\ntrainer_stats = trainer.train()\n","metadata":{"ExecuteTime":{"end_time":"2025-03-15T16:43:20.769353Z","start_time":"2025-03-15T16:43:12.969188Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"训练后推理结果：\")\nprint(inference_example(text))","metadata":{"ExecuteTime":{"end_time":"2025-03-15T16:43:32.913808Z","start_time":"2025-03-15T16:43:20.831207Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 使用你的 Hugging Face 令牌登录\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\nlogin(token=hf_token)\nnew_model_local = \"DeepSeek-R1-Sentiment-COT\"\nmodel.save_pretrained(new_model_local)\ntokenizer.save_pretrained(new_model_local)\nmodel.save_pretrained_merged(new_model_local, tokenizer, save_method=\"merged_16bit\")\n","metadata":{"ExecuteTime":{"end_time":"2025-03-15T16:43:46.033231Z","start_time":"2025-03-15T16:43:32.979552Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_model_online = \"MelodyOfTears/DeepSeek-R1-Sentiment-COT\"\nmodel.push_to_hub(new_model_online)\ntokenizer.push_to_hub(new_model_online)\nmodel.push_to_hub_merged(new_model_online, tokenizer, save_method=\"merged_16bit\")","metadata":{},"outputs":[],"execution_count":null}]}