{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:13:41.730532Z",
     "start_time": "2025-03-23T06:13:35.013406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Notebook Name: Generate_CoT_Sentiment_Analysis.ipynb\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from datasets import load_dataset, Value\n",
    "from huggingface_hub import login"
   ],
   "id": "3c033a19e30b7b5f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:13:41.746207Z",
     "start_time": "2025-03-23T06:13:41.730532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Load API keys from environment variables\n",
    "# api_key = os.getenv(\"DeepSeek_API_KEY\")\n",
    "# hf_token = os.getenv(\"HF_TOKEN\")\n",
    "#\n",
    "# # Ensure API keys are available\n",
    "# if not api_key or not hf_token:\n",
    "#     raise ValueError(\"Missing API keys! Set 'DeepSeek_API_KEY' and 'HF_TOKEN' as environment variables.\")"
   ],
   "id": "d20103f2cc99cf2b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load API keys from Kaggle Secrets\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "\n",
    "def load_kaggle_secrets():\n",
    "    \"\"\"\n",
    "    Load API keys from Kaggle Secrets.\n",
    "    \"\"\"\n",
    "    user_secrets = UserSecretsClient()\n",
    "    api_key = user_secrets.get_secret(\"DeepSeek_API_KEY\")\n",
    "    hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "    return api_key, hf_token\n",
    "\n",
    "\n",
    "# Load API keys\n",
    "api_key, hf_token = load_kaggle_secrets()\n",
    "\n",
    "# Ensure API keys are available\n",
    "if not api_key or not hf_token:\n",
    "    raise ValueError(\"Missing API keys! Add 'DeepSeek_API_KEY' and 'HF_TOKEN' to your Kaggle Secrets.\")"
   ],
   "id": "6bfc82e611c1bfb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:13:41.769771Z",
     "start_time": "2025-03-23T06:13:41.753330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to initialize the API client\n",
    "def initialize_api_client(api_key):\n",
    "    \"\"\"\n",
    "    Initialize the OpenAI client with DeepSeek API.\n",
    "    \"\"\"\n",
    "    return OpenAI(\n",
    "        api_key=api_key,\n",
    "        base_url=\"https://api.deepseek.com\"\n",
    "    )"
   ],
   "id": "ade10dc2b6322c79",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:13:42.173502Z",
     "start_time": "2025-03-23T06:13:42.155873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to generate Chain of Thought reasoning\n",
    "def generate_cot(client, text, label, max_retries=3):\n",
    "    \"\"\"\n",
    "    Generate a Chain of Thought (CoT) explanation for sentiment analysis.\n",
    "    \"\"\"\n",
    "    sentiment_map = {0: \"negative\", 1: \"positive\"}\n",
    "\n",
    "    prompt = f\"\"\"As a sentiment analysis expert, generate a step-by-step Chain of Thought (CoT) in English to explain why the following text is {sentiment_map[label]}.\n",
    "The CoT should follow this structure:\n",
    "1. Identify key sentiment-bearing words/phrases\n",
    "2. Analyze contextual clues\n",
    "3. Consider linguistic patterns\n",
    "4. Synthesize overall sentiment\n",
    "5. Conclude with the final sentiment label (0 for negative, 1 for positive)\n",
    "\n",
    "Text: {text}\n",
    "CoT:\"\"\"\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"deepseek-chat\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an expert in sentiment analysis and logical reasoning.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.7,\n",
    "                max_tokens=300,\n",
    "                stream=False\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"Attempt {attempt+1} failed, retrying...\")\n",
    "                time.sleep(2)\n",
    "            else:\n",
    "                print(f\"Failed after {max_retries} attempts: {str(e)}\")\n",
    "                return \"CoT generation failed\""
   ],
   "id": "cdf55491a4833f14",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:13:42.220771Z",
     "start_time": "2025-03-23T06:13:42.207102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to add CoT to the dataset\n",
    "def add_cot_to_dataset(client, dataset, sample_size=None, sleep_time=1):\n",
    "    \"\"\"\n",
    "    Add Chain of Thought explanations to a dataset.\n",
    "    \"\"\"\n",
    "    if sample_size:\n",
    "        dataset = dataset.select(range(min(sample_size, len(dataset))))\n",
    "\n",
    "    texts = dataset[\"sentence\"]\n",
    "    labels = dataset[\"label\"]\n",
    "\n",
    "    cots = []\n",
    "    for text, label in tqdm(zip(texts, labels), total=len(texts)):\n",
    "        cot = generate_cot(client, text, label)\n",
    "        cots.append(cot)\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "    return dataset.add_column(\"Complex_CoT\", cots)\n"
   ],
   "id": "59637dff947b1180",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:13:42.257524Z",
     "start_time": "2025-03-23T06:13:42.238530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to upload the dataset to Hugging Face\n",
    "def upload_to_huggingface(dataset, dataset_name, hf_token, is_private=False):\n",
    "    \"\"\"\n",
    "    Upload the enhanced dataset to Hugging Face Hub.\n",
    "    \"\"\"\n",
    "    login(token=hf_token)\n",
    "\n",
    "    dataset = dataset.cast_column(\"Complex_CoT\", Value(\"string\"))\n",
    "    # 设置数据集的描述信息\n",
    "    dataset.info.description = \"SST-2 dataset enhanced with Chain-of-Thought reasoning for sentiment analysis.\"\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Uploading dataset to {dataset_name}...\")\n",
    "    dataset.push_to_hub(repo_id=dataset_name, private=is_private, token=hf_token)\n",
    "    print(f\"Dataset successfully uploaded to {dataset_name}\")\n"
   ],
   "id": "c658f276ee506ab9",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T06:13:42.289453Z",
     "start_time": "2025-03-23T06:13:42.275408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Main function to generate and upload the CoT dataset\n",
    "def create_cot_dataset(api_key, hf_token, dataset_name, sample_size=None):\n",
    "    \"\"\"\n",
    "    Create and upload a Chain of Thought dataset for sentiment analysis.\n",
    "    \"\"\"\n",
    "    client = initialize_api_client(api_key)\n",
    "\n",
    "    print(\"Loading SST-2 dataset...\")\n",
    "    dataset = load_dataset(\"glue\", \"sst2\", split=\"train[:1]\")\n",
    "\n",
    "    print(\"Generating Chain of Thought explanations...\")\n",
    "    enhanced_dataset = add_cot_to_dataset(client, dataset, sample_size=sample_size)\n",
    "\n",
    "    upload_to_huggingface(enhanced_dataset, dataset_name, hf_token)\n",
    "\n",
    "    return enhanced_dataset\n"
   ],
   "id": "f498ecb8b3980a8d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-23T06:13:42.305505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define dataset name\n",
    "dataset_name = \"MelodyOfTears/sst2-with-cot\"\n",
    "\n",
    "# Create and upload the dataset\n",
    "enhanced_dataset = create_cot_dataset(api_key, hf_token, dataset_name)"
   ],
   "id": "63393ddc9af581eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SST-2 dataset...\n",
      "Generating Chain of Thought explanations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 8/500 [02:16<2:18:49, 16.93s/it]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Print an example\n",
    "print(enhanced_dataset[0]['Complex_CoT'])"
   ],
   "id": "120fece0478ab667"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
